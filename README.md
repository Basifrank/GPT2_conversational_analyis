[![Build Status](https://travis-ci.org/timolinn/hng.tech.svg?branch=master)](https://travis-ci.org/timolinn/hng.tech)

<div align="center">

![hng](https://res.cloudinary.com/iambeejayayo/image/upload/v1554240066/brand-logo.png)

<br>

</div>

# GPT2_conversational_analyis

## Conversational Analysis Report on GPT-2 Model

The GPT-2 model is a Natural language processing model, created by openai. It is a high-level NLP model that can be used for reading comprehension, text completion, summarization, translation, and question-answering when trained with a dataset.
The team task is to train and fine-tune the model with Kaggle ubuntu data and make report on the findings.


# Testing

-	Open on Google colab
-	importing libraries
-	The ubuntu data was downloaded using the Kaggle api
-	cloning git repo to
-	installing necessary requirements
-	Download the model
-	Cleaning data
-	Parsing data to model
-	Encoding data
-	Training data
-	generate conversations on its own 
-	generate sample articles on its own base on the trained data.

### The model was finetuned by making changes to the model’s learning_rate, stop_after and the following flags
•	model_name = Model 345M remained constant
•	nsamples 
•	length 
•	temperature
•	top_k 

## colab link
- https://colab.research.google.com/drive/1z9USq-MDuaSvdSTMgFc_Y_xn2Rx2Y_1Q

# Findings/Observations

-	For generate_unconditional_samples.py --top_k 40 --temperature 1 --model_name 345M, model generated articles continuously, ended when the program was abruptly stopped at the run command.

-	For interactive_conditional_samples.py  --model_name='345M'  --nsamples=20 --top_k=40 --temperature=.90 --length=1, model was fed with a line of text which was spread across 20 sample parts

-	For interactive_conditional_samples.py --model_name='345M' --nsamples=2 --top_k=40 --temperature=.90 model was fed with a input sentence, two text completion articles was generated by the model

-	For interactive_conditional_samples.py --model_name='345M'  --nsamples=5 --temperature=1 model was fed with an input sentence, five sample sentences was created by the model with names of Russia’s president and first lady

-	For src/interactive_conditional_samples.py --model_name='345M'  --top_k 40 --temperature 0.9 
A conversational and a comprehension with question, was fed to the model, for the conversational the model predicted the name Ioannis Agathocleous and completed a description of the who the name is and what he wants to do. For the comprehension with question, the mod
	
